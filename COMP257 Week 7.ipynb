{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis\n",
    "\n",
    "The exercise this week is to work with a time series data set to try to predict the future values from those in the past.  The procedure was outlined in the lecture last week.  The dataset we will use is of measures of average carbon dioxide ($CO_2$) concentration taken each month from 1958 onwards, hosted [here](https://www.esrl.noaa.gov/gmd/ccgg/trends/data.html) by the US National Oceanic & Atmospheric Administration.  \n",
    "\n",
    "The data shows a clear upward trend over time with seasonal oscillations.  The first task is to load the data into a Pandas time series.  You should have a look at [the data file](files/co2_mm_mlo.txt).  Note that this data is available as a text file with whitespace delimeters between columns and that there are comment lines at the start of the file that we must skip. I have to provide the column names explicitly.  NA values in the data are encoded as -1, so we use the `na_values` argument to `read_table` to recognise these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn import linear_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default figure size\n",
    "plt.rcParams['figure.figsize'] = 15, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2 = pd.read_table('files/co2_mm_mlo.txt', delim_whitespace=True, comment=\"#\", \n",
    "                    names=['year', 'month', 'decdate', 'average', 'interp', 'trend', 'days'],\n",
    "                   na_values=\"-1\")\n",
    "co2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a date index, since the data includes just year and month colums, we add a constant `day` column to use in creating the datetime index.  We then remove the columns from the dataframe that aren't relevant (all except 'average') and drop any rows that contain NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2['day'] = 1\n",
    "co2.index = pd.to_datetime(co2[['year', 'month', 'day']])\n",
    "co2.drop(['day', 'days', 'interp', 'trend', 'decdate', 'year', 'month'], axis=1, inplace=True)\n",
    "co2.dropna(inplace=True)\n",
    "co2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data frame is not evenly spaced - there are some months that don't have any data.   To properly analyse the time series we need it to be evenly spaced, so we use the `resample` method to create a new version.  The `bfill` method here creates a new time series with unknown values _back filled_ from the next time point.  Observe the effect on the data for 1958-06-01 here that is missing in the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample to get even frequency - fill unknown values\n",
    "co2rs = co2.resample('MS').bfill()\n",
    "co2rs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we make a column `elapseddays` to contain a count of the number of days from the start for each row. This will be used as our `x` value for modelling later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column with the number of days since the first sample\n",
    "co2rs['elapseddays'] = (co2rs.index - co2rs.index[0]).days\n",
    "co2rs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Task\n",
    "\n",
    "Ok, now you take over.  Your goal is to first make the time series stationary, then to model the transformed time-series using an ARIMA model.   A strong hint is that there is a clear trend line in the data so computing a rolling mean that you then subtract from the `average` column is the way to go.\n",
    "\n",
    "First, test the time-series for stationarity using the functions defined in the lecture and reproduced here.  Then compute the rolling mean, subtract it from the average column and repeat the test on these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stationarity(timeseries, window=12):\n",
    "    \"\"\"Generate rolling plots of the time series\"\"\"\n",
    "    \n",
    "    #Determing rolling statistics\n",
    "    rolmean = timeseries.rolling(window=window,center=False).mean() \n",
    "    rolstd = timeseries.rolling(window=window,center=False).std() \n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "\n",
    "def test_stationarity(timeseries, window=12):\n",
    "    \"\"\"Run the Dickey-Fuller test for stationarity\"\"\"\n",
    "  \n",
    "    #Perform Dickey-Fuller test:\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], \n",
    "                         index=['Test Statistic','p-value',\n",
    "                                '#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stationarity(co2rs['average'])\n",
    "test_stationarity(co2rs['average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the rolling mean of the 'average' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rolling mean introduces some NaN values at the start\n",
    "# use the dropna method to remove the rows containing NaN values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract the rolling mean from the average to give a normalised time series, add it as a new column to the data frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the stationarity of the new time series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit ARIMA Model\n",
    "\n",
    "Your next task is to fit an ARIMA model to the normalised column.  First we split the data into training and testing partitions.  We use the first 650 points for trianing and the remainder for testing.   Note that we use the copy method for the test data to get a copy rather than a view on the original data frame since we will want to add new columns for our predictions later. \n",
    "\n",
    "Esitmate the order of model that you should use (coefficients $p$ and $q$) and then build and train an ARIMA model. Plot the fitted values overlayed with the orginal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing data\n",
    "train = co2rs.iloc[:650]\n",
    "test = co2rs.iloc[650:].copy()  # copy this because we want to add to it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train an ARIMA model\n",
    "armodel = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now that you have a model you can make predictions for the unknown time points in the test data and compare these to the true values.  To do this you can use the [`forecast` method of the ARIMA model](https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima_model.ARMAResults.forecast.html) which returns three arrays (forecast, error, confidence).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# forecast as many points as are in our test data\n",
    "forecast, error, conf = armodel.forecast(steps=test.average.size)\n",
    "# add them to the data frame and plot\n",
    "test['forecast'] = forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the actual and forecast values together\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model of trend over time\n",
    "\n",
    "Next we look at the rolling mean of the original average co2 time series which was subtracted from the original to allow us to fit the ARIMA model.  We can see that this is a gradual increase over time so we could predict future values using a linear model.  \n",
    "\n",
    "Fit a linear model to predict `rolling` from `elapseddays` on the training data. Use it to predict future values for the test data, add these values as a new column to the test data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the rolling mean vs elapseddays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a linear model and predict the co2 average for each of the values in elapseddays in the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Prediction\n",
    "\n",
    "Now that we have predictions for both the overall trend and the seasonal variation in CO2 average they can be combined to give an overall prediction for the CO2 values in the range of the test data.  Compute this value and plot the true and predicted average values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
